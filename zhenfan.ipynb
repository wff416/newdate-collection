{
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "name": "python", 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "execution_count": 4, 
            "cell_type": "code", 
            "source": "from pyspark import SparkContext\nimport ibmos2spark\nimport time\nimport boto3\nimport sys\nimport pprint\nfrom pyspark.sql import Row\nimport xml.etree.ElementTree as ET\nfrom pyspark.sql import SparkSession\nimport shutil\nfrom io import BytesIO\nimport scandir\nimport json\nimport os\nreload(sys)\nsys.setdefaultencoding('utf-8')\nsqlContext = SQLContext(sc)\nurls=[\"anibis.ch\",\n                    \"autoscout24.ch\",\n                    \"objectif-moto\",\n                    \"ldlc.be\",\n                    \"annonces-automobile.com\",\n                    \"artmajeur.com\",\n                    \"mobilectrl.de/\",\n                    \"feuerstuhl.net\",\n                    \"tauschgnom.de\",]\nlanguage_code={\n           \"french\":\"fr\",\n           \"german\":\"de\",\n           \"italian\":'it',\n           \"japanese\":\"ja\"\n        }\n\ncredentials = {\n            'endpoint': 's3-api.us-geo.objectstorage.softlayer.net',\n            'access_key': '0b5378b16d334898ad3a30941640a18f',\n            'secret_key': '4320f5522224a623439e3fc0613089d5628c044596abc6b5'\n        }\n#targetdir=\"/gpfs/global_fs01/sym_shared/YPProdSpark/user/sd1f-f9329d4abc7e63-0f85d1536d65/notebook/work/newsdata_\"+time.strftime(\"%d-%m-%Y\")+\"/\"\ntargetdir=\"/gpfs/global_fs01/sym_shared/YPProdSpark/user/sd1f-f9329d4abc7e63-0f85d1536d65/notebook/work/test/\"\nlanguage=\"french\"\nbucket_name = 'blueumbrella-r1ix4buf-catalog-db12db8b'\ncos = boto3.client('s3', endpoint_url=\"https://s3-api.us-geo.objectstorage.softlayer.net\",aws_access_key_id=credentials['access_key'],aws_secret_access_key=credentials[\"secret_key\"])\ncos_res=boto3.resource('s3', endpoint_url=\"https://s3-api.us-geo.objectstorage.softlayer.net\",aws_access_key_id=credentials['access_key'],aws_secret_access_key=credentials[\"secret_key\"])\nconfiguration_name = 'cos_config_string'  #you can give any string you like\ncos_spark = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name=configuration_name)\nspark = SparkSession.builder.getOrCreate()\n\ndef check_duplicate(language,type,date,keyword):\n    path=\"nlu/\"+\"fr\"+\"/filtered/news/2017-10-06/headline_fr_news_f_20171006.csv\"\n    url=cos_spark.url(path,'blueumbrella-r1ix4buf-catalog-db12db8b')\n    data=spark.read.format('com.databricks.spark.csv').options(header='true',inferSchema='true').load(url)\n    data.registerTempTable('headline')\n    cnt=sqlContext.sql('select ID from headline where news_headline_fr_news_f_20171006=\"'+keyword+'\"').count()       \n    return cnt\n\ndef make_manifest(code,description,tags,owner,dir):\n    data= {}\n    data[\"description\"]=\"News Raw Data\"\n    data['language']=code\n    data['tags']=[]\n    for tag in tags:\n        data['tags'].append(tag)\n    data['owner']=owner\n    json_data=json.dumps(data)\n    outfile=open(dir+\"manifest.json\",\"w\")\n    json.dump(json_data,outfile,indent=2)\n    \n    \ndef load_raw_cos(date,language):\n        code=language_code[language]\n        #path=\"raw/\"+code+\"/news/webhose/common_\"+code+\"_news_r_\"+date+\"/data/\"\n        path=\"audio/test/\"\n        objects = cos.list_objects(Bucket=bucket_name,Prefix=path)\n        file_lst=[]\n        for obj in objects['Contents']:\n            if \".xml\" in obj[\"Key\"]:\n                file_lst.append(obj[\"Key\"])\n            \n        for file_name in file_lst:\n            print file_name\n            content=cos.get_object(Bucket=bucket_name,Key=file_name)\n            parse_xml(content[\"Body\"].read(),file_name.split('/')[-1])\n\ndef parse_xml(content,file):\n        #tree=ET.parse(content)\n        #root=tree.getroot()\n        root=ET.fromstring(content)\n        language=root.find('language').text\n        path=targetdir\n        url=root.find('topic_url').text\n        if not check_urls(url):\n            path=targetdir+language+\"/\"\n            title=root.find('discussion_title').text\n            title_id=file[0:-4]+\"_title\"\n            topic_id=file[0:-4]+\"_topic\"\n            content=root.find('topic_text').text\n            if title:\n                if '\"' in title:\n                    title=title.replace('\"',\"'\")\n                if check_duplicate(\"french\",\"headline\",\"\",title)<1:    \n                    title_str='\"'+str(title_id)+'\",\"'+str(title)+'\",\"'+language+'\",\"'+\"news_headline\"+'\"\\n'\n                    filename=path+\"headline.csv\"\n                    f=open(filename,'a+')\n                    f.write(title_str)\n                if content:                                \n                    if '\"' in content:\n                        content=content.replace('\"',\"'\")\n                content=filter_title(content,title,topic_id)\n                if check_duplicate(\"french\",\"article\",\"\",content)<1:\n                    topic_str='\"'+str(topic_id)+'\",\"'+content+'\",\"'+language+'\",\"'+\"news_article\"+'\"\\n'\n                    filename=path+\"article.csv\"\n                    f=open(filename,'a+')\n                    f.write(topic_str)\n                i=1\n                for post in root.findall('post'):\n                    comment=post.text\n                    if comment:\n                        content1=\"\".join([c if c.isalnum() else \"\" for c in content])\n                        comment1=\"\".join([c if c.isalnum() else \"\" for c in comment])\n                        if content1!=comment1:\n                            if '\"' in comment:\n                                comment=comment.replace('\"',\"'\")\n                            if check_duplicate(\"french\",\"comment\",\"\",comment)<1:    \n                                post_id=file[0:-4]+\"_comment_\"+str(i)\n                                i+=1\n                                post_str='\"'+str(post_id)+'\",\"'+str(comment)+'\",\"'+language+'\",\"'+\"news_comment\"+'\"\\n'\n                                filename=path+\"comment.csv\"\n                                f=open(filename,'a+')\n                                f.write(post_str)\n                            \ndef filter_title(article,title,id):\n        if title:\n            pos=article.find(title)                        \n            if pos!=-1:\n                #print id\n                return article[pos+len(title):]\n        return article   \n    \ndef check_urls(url):\n        for u in urls:\n            if u in url:\n                return True\n        \n        return False    \n    \ndef setup():\n        try:\n            dr=targetdir+language\n            shutil.rmtree(dr)\n        except:\n            pass\n        os.makedirs(dr)\n        for file in [\"headline.csv\",\"article.csv\",\"comment.csv\"]:\n            f=open(dr+\"/\"+file,'a+')\n            st=\"ID,news_\"+file[:-4]+\",language,data_source\\n\"\n            f.write(st)    \n    \ndef upload_filtered_COS():\n        print \"BEGIN UPLOAD: \"\n\n        for root,dirs,files in scandir.walk(targetdir):\n            for d in dirs:\n                language=language_code[d]\n                path_to_upload=\"nlu/\"+language+\"/filtered/news/\"+targetdir.split('_')[1]+\"/\"\n                make_manifest(language,\"News Filtered Data\",path_to_upload.split(\"/\"),\"wuf@us.ibm.com\",targetdir+d+\"/\")\n                for root,dirs,files in scandir.walk(targetdir+d):\n                    for file in files:\n                        cos.upload_file(targetdir+d+\"/\"+file,\"blueumbrella-r1ix4buf-catalog-db12db8b\", path_to_upload+file)\n                        os.remove(targetdir+d+\"/\"+file)\n        print \"END UPLOAD \"   \nsetup()\nload_raw_cos(\"\",\"french\") \nupload_filtered_COS()", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "source": "ls", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 10, 
            "cell_type": "code", 
            "source": "pwd", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "u'/gpfs/global_fs01/sym_shared/YPProdSpark/user/sd1f-f9329d4abc7e63-0f85d1536d65/notebook/work/test'"
                    }, 
                    "execution_count": 10, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 11, 
            "cell_type": "code", 
            "source": "cd test", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 12, 
            "cell_type": "code", 
            "source": "ls", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}